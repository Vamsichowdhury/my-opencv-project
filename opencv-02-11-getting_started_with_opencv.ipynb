{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vamsi krishna\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imread is used to read an image\n",
    "input=cv2.imread(r\"C:\\Users\\vamsi krishna\\Animal World.jpeg\")\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720, 3)\n"
     ]
    }
   ],
   "source": [
    "# It has 1280 rows pixels,720 columns pixels\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height of image: 1280 pixels\n",
      "width of image: 720 pixels\n",
      "RGB values of image: 3\n",
      "total pixels in image: 2764800\n"
     ]
    }
   ],
   "source": [
    "print(\"height of image:\",int(input.shape[0]),'pixels')\n",
    "print(\"width of image:\",int(input.shape[1]),'pixels')\n",
    "print(\"RGB values of image:\",int(input.shape[2]))\n",
    "print('total pixels in image:',input.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grayscaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### it is a process by which an image is converted from a full color to shades of grey(black&white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greay scaling is done  because it simplifies the image,acting almost as a noise reduction,increasing processing time as there is less information in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#load our input image\n",
    "image=cv2.imread(r\"C:\\Users\\vamsi krishna\\Animal World.jpeg\")\n",
    "cv2.imshow('original',image)\n",
    "cv2.waitKey()\n",
    "\n",
    "# we use cvtColor,to convert to greyscale\n",
    "gray_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('grayscale image',gray_image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# load our image\n",
    "# imread take path to image as parameter\n",
    "\n",
    "image=cv2.imread(r\"C:\\Users\\vamsi krishna\\love.jpeg\")\n",
    "\n",
    "# imshow takes two parameters   1.name of image and input image to show\n",
    "cv2.imshow(\"original image\",image)\n",
    "cv2.waitKey()\n",
    "\n",
    "grey_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"GREY IMAGE\",grey_image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First thing to remember about opencv's RGB is that these colors are storeed in BGR format in array in opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r\"C:\\Users\\vamsi krishna\\love.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image variable maximum of 1280 rows pixels and 720 columns pixels\n",
    "# image[0,0]--pixel in zeroth index row or first row ,zeroth index column or first column\n",
    "# image[0,100]---pixel in zeroth row ,100th column\n",
    "# image[100,719]--- 100th row and 719th column\n",
    "\n",
    "B,G,R=image[1279,700]\n",
    "print(B,G,R)\n",
    "print(image.shape)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets see what happend when converted image into grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "B=gray_image[1279,700]\n",
    "print(gray_image.shape)\n",
    "print(B)\n",
    "print(gray_image)\n",
    "\n",
    "# previously image contains a pixel with color combinations of red,\n",
    "# green,blue and it \n",
    "# now gray_image contains a pixel having single value and that \n",
    "# single value ranges from 0(white) to 255(black)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infact hsv is very useful in color filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image=cv2.imread(r\"C:\\Users\\vamsi krishna\\love.jpeg\")\n",
    "hsv_image=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"hsv image\",hsv_image)\n",
    "cv2.imshow(\"hue channel\",hsv_image[:,:,0])\n",
    "cv2.imshow(\"saturation channel\",hsv_image[:,:,1])\n",
    "cv2.imshow(\"value channel\",hsv_image[:,:,2])\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at individual channels in an RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image=cv2.imread(r\"C:\\Users\\vamsi krishna\\love.jpeg\")\n",
    "# opencv's \"split\" function splits the image into each color complex\n",
    "B,G,R=cv2.split(image)\n",
    "\n",
    "# print(B[0:10,0:10])# in the image BLUE is less\n",
    "# print(G[0:10,0:10])# in the image GREEN is less\n",
    "# print(R[0:10,0:10])# in the image red is more\n",
    "\n",
    "# print(B.shape) GIVES (1280,720)\n",
    "#\n",
    "print(G.shape)    ''\n",
    "# print(R.shape)    ''\n",
    "\n",
    "cv2.imshow(\"ORIGINAL IMAGE\",image)\n",
    "cv2.imshow(\"BLUE\",B)\n",
    "cv2.imshow(\"GREEN\",G)\n",
    "cv2.imshow(\"RED\",R)\n",
    "cv2.waitKey()\n",
    "\n",
    "# lets remake the original image\n",
    "merged=cv2.merge([B,G,R])\n",
    "cv2.imshow('MERGED',merged)\n",
    "cv2.waitKey()\n",
    "\n",
    "# lets amplify BLUE color\n",
    "bmerged=cv2.merge([B+255,G,R])# max of 255 can be added \n",
    "cv2.imshow(\"blue merged image\",bmerged)\n",
    "cv2.waitKey()\n",
    "\n",
    "# lets amplify GREEN color\n",
    "gmerged=cv2.merge([B,G-255,R])# min of 255 can be subtracted(gives original image)\n",
    "cv2.imshow(\"green merged image\",gmerged)\n",
    "cv2.waitKey()\n",
    "\n",
    "# lets amplify RED color\n",
    "rmerged=cv2.merge([B,G,R+100])\n",
    "cv2.imshow(\"red merged image\",rmerged)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing images and shapes using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# creating  a black image\n",
    "image=np.ones((512,512,3),np.uint8)\n",
    "\n",
    "# black and white \n",
    "image_bw=np.zeros((512,512),np.uint8)\n",
    "\n",
    "cv2.imshow(\"Black Rectangle(color)\",image)\n",
    "cv2.imshow(\"Black Rectangle(b&w)\",image_bw)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((256,256,3),np.uint8)\n",
    "\n",
    "# we will draw a line on image starting at (0,0) ending at(511,511),blue color,5 pixel thickness\n",
    "cv2.line(image,(0,0),(29,255),(255,0,0),5)\n",
    "#cv2.imshow(\"BLUE LINE\",image)\n",
    "cv2.line(image,(0,0),(55,55),(0,255,0),5)\n",
    "#cv2.imshow(\"GREEN LINE\",image)\n",
    "cv2.line(image,(0,0),(100,255),(0,0,255),5)\n",
    "cv2.imshow(\"RED LINE\",image)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=np.zeros((256,256,3),np.uint8)\n",
    "cv2.rectangle(image,(20,20),(150,150),(255,0,0),3)\n",
    "cv2.rectangle(image,(50,50),(150,150),(0,255,0),3)\n",
    "cv2.rectangle(image,(110,200),(150,150),(0,0,255),3)\n",
    "#cv2.rectangle(image,(230,230),(150,150),(255,0,0),3)\n",
    "cv2.imshow(\"RECTANGLE\",image)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.putText(image,\"Text to Display\",bottom left starting point,Font,Font Size,Color,Thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FONT_HERSHEY_COMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((512,512,3),np.uint8)\n",
    "\n",
    "cv2.putText(image,\"Hello,World! I am VAMSI\",(50,250),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),1)\n",
    "cv2.imshow(\"hello world\",image)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transalations\n",
    "\n",
    "#### This is an affine transform that simply shifts the position of an image\n",
    "#### we use cv2.warpAffine to implement the transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r\"C:\\Users\\vamsi krishna\\love.jpeg\")\n",
    "\n",
    "# strre height and width of image\n",
    "height,width=image.shape[:2]\n",
    "\n",
    "quarter_height,quarter_width=height/4,width/4\n",
    "\n",
    "# T is our translation matrix\n",
    "T=np.float32([[1,0,quarter_height],[0,1,quarter_width]])\n",
    "\n",
    "# cv.warpAffine() is used to shift positions of image\n",
    "# Third argument of the cv.warpAffine() function is the size of the output image, \n",
    "# which should be in the form of **(width, height)**. Remember width = number of columns, and height = number of rows.\n",
    "img_translation=cv2.warpAffine(image,T,(width,height))\n",
    "cv2.imshow(\"Translation\",img_translation)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations\n",
    "\n",
    "#### cv2.getRotationMatrix2D(rotation_centre_x,rotation_centre_y,angle of rotation,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r\"C:\\Users\\vamsi krishna\\medicine.jpg\")\n",
    "height,width=image.shape[0:2]\n",
    "rotation_matrix=cv2.getRotationMatrix2D((width/2,height/2),0,.5)\n",
    "\n",
    "rotated_image=cv2.warpAffine(image,rotation_matrix,(225,225))\n",
    "\n",
    "\n",
    "#cv2.imshow(\"original image\",image)\n",
    "cv2.imshow(\"rotated image\",rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### black space can be removed by using cv2.transpose function for simple rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_image_method2=cv2.transpose(image)\n",
    "cv2.imshow(\"rotated_image_method2\",rotated_image_method2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total faces found: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#load the image to detect\n",
    "image=cv2.imread(r\"C:\\Users\\vamsi krishna\\picbday.jpeg\")\n",
    "#convert it into gray image\n",
    "gray_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# LOAD THE CLASSIFIER\n",
    "classifier=cv2.CascadeClassifier(r\"C:\\Users\\vamsi krishna\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#APPLY THE CLASSIFIER ON IMAGE\n",
    "faces_rects=classifier.detectMultiScale(gray_image,scaleFactor=1.6,minNeighbors=3)\n",
    "print(\"Total faces found:\",len(faces_rects))\n",
    "\n",
    "for (x,y,w,h) in faces_rects:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "# show images\n",
    "cv2.imshow(\"original image\",image)\n",
    "cv2.imshow(\"gray image\",gray_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pillow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e32915389b2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpillow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pillow'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
